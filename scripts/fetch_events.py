# Python 3.10+
import os, re, time, json
from pathlib import Path

import requests
import pandas as pd
from geopy.geocoders import ArcGIS
from geopy.extra.rate_limiter import RateLimiter

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ –ù–ê–°–¢–†–û–ô–ö–ò ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
TOKEN        = os.getenv("VK_TOKEN")                 # ‚¨ÖÔ∏è –¥–æ–±–∞–≤—å —Å–µ–∫—Ä–µ—Ç –≤ GitHub ‚Üí Settings ‚Üí Secrets ‚Üí Actions
DOMAIN       = os.getenv("VK_DOMAIN", "meowafisha")  # –ø–∞–±–ª–∏–∫ –í–ö (–º–æ–∂–Ω–æ –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Å–µ–∫—Ä–µ—Ç–æ–º/–≤–∞—Ä–æ–º)
MAX_POSTS    = int(os.getenv("VK_MAX_POSTS", "2000"))
BATCH        = 100
WAIT_REQ     = 1.1                                   # –ø–∞—É–∑–∞ –º–µ–∂–¥—É wall.get (~1 rps)
WAIT_GEO     = 1.0                                   # –ø–∞—É–∑–∞ ArcGIS (‚âà1000/—Å—É—Ç–∫–∏)
YEAR_DEFAULT = os.getenv("YEAR_DEFAULT", "2025")

OUTPUT_JSON  = Path("events.json")                   # –≤–∞–∂–Ω–æ: –ª–µ–∂–∏—Ç —Ç–∞–º, –æ—Ç–∫—É–¥–∞ –µ–≥–æ —Ä–∞–∑–¥–∞—Å—Ç Pages
CACHE_FILE   = Path("geocode_cache.json")            # –∫–æ–º–º–∏—Ç–∏–º –∫—ç—à ‚Äî —ç–∫–æ–Ω–æ–º–∏—Ç –ª–∏–º–∏—Ç

assert TOKEN, "VK_TOKEN –Ω–µ –∑–∞–¥–∞–Ω"

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
vk_url = "https://api.vk.com/method/wall.get"
geo = RateLimiter(ArcGIS(timeout=10).geocode, min_delay_seconds=WAIT_GEO)

# –ö—ç—à –∞–¥—Ä–µ—Å‚Üí(lat, lon)
if CACHE_FILE.exists():
    geocache = json.loads(CACHE_FILE.read_text(encoding="utf-8"))
else:
    geocache = {}

def vk_wall(offset: int):
    params = dict(domain=DOMAIN, offset=offset, count=BATCH,
                  access_token=TOKEN, v="5.199")
    r = requests.get(vk_url, params=params, timeout=20)
    r.raise_for_status()
    data = r.json()
    # fail-safe: —É VK –æ—à–∏–±–∫–∏ –±—ã–≤–∞—é—Ç –≤ "error"
    if "error" in data:
        raise RuntimeError(f"VK API error: {data['error']}")
    return data["response"]["items"]

CITY_WORDS = r"(–∫–∞–ª–∏–Ω–∏–Ω–≥—Ä–∞–¥|–≥—É—Ä—å–µ–≤—Å–∫|—Å–≤–µ—Ç–ª–æ–≥–æ—Ä—Å–∫|—è–Ω—Ç–∞—Ä–Ω—ã–π)"

def extract(text: str):
    # –¥–∞—Ç–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ –î–î.–ú–ú
    m_date = re.search(r"\b(\d{2})\.(\d{2})\b", text)
    # –ª–æ–∫–∞—Ü–∏—è –ø–æ—Å–ª–µ üìç
    m_loc  = re.search(r"üìç\s*(.+)", text)
    if not (m_date and m_loc):
        return None

    date  = f"{YEAR_DEFAULT}-{m_date.group(2)}-{m_date.group(1)}"
    loc   = m_loc.group(1).split('‚û°Ô∏è')[0].strip()
    if not re.search(CITY_WORDS, loc, re.I):
        loc += ", –ö–∞–ª–∏–Ω–∏–Ω–≥—Ä–∞–¥"

    # –∑–∞–≥–æ–ª–æ–≤–æ–∫ = –ø–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞ –±–µ–∑ "–î–î.–ú–ú |"
    first_line = text.split('\n', 1)[0]
    title = re.sub(r"^\s*\d{2}\.\d{2}\s*\|\s*", "", first_line).strip()

    return dict(title=title, date=date, location=loc)

def geocode(addr: str):
    if addr in geocache:
        return geocache[addr]
    try:
        g = geo(addr)
        if g:
            geocache[addr] = [g.latitude, g.longitude]
        else:
            geocache[addr] = [None, None]
    except Exception:
        geocache[addr] = [None, None]
    return geocache[addr]

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ –°–ë–û–† –ü–û–°–¢–û–í ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
records, off = [], 0
while off < MAX_POSTS:
    items = vk_wall(off)
    if not items:
        break
    for it in items:
        text = it.get("text") or ""
        evt = extract(text)
        if evt:
            records.append(evt)
    off += BATCH
    time.sleep(WAIT_REQ)

print("–ê–Ω–æ–Ω—Å–æ–≤ –Ω–∞–π–¥–µ–Ω–æ:", len(records))
if not records:
    # –Ω–∏—á–µ–≥–æ –Ω–µ –ª–æ–º–∞–µ–º: —Å–æ—Ö—Ä–∞–Ω—è–µ–º –ø—É—Å—Ç–æ–π –º–∞—Å—Å–∏–≤
    OUTPUT_JSON.write_text("[]", encoding="utf-8")
    raise SystemExit(0)

df = pd.DataFrame(records).drop_duplicates()

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ –ì–ï–û–ö–û–î–ò–ù–ì ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
lats, lons = [], []
for addr in df["location"]:
    lat, lon = geocode(addr)
    lats.append(lat); lons.append(lon)
df["lat"] = lats; df["lon"] = lons

bad_cnt = int(df["lat"].isna().sum())
df = df.dropna(subset=["lat", "lon"])

print(f"–° –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º–∏: {len(df)} | –±–µ–∑ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç: {bad_cnt}")

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ –°–û–•–†–ê–ù–ï–ù–ò–ï ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
df = df[["title","date","location","lat","lon"]].sort_values("date")
OUTPUT_JSON.write_text(df.to_json(orient="records", force_ascii=False, indent=2), encoding="utf-8")

# –∫—ç—à —Ç–æ–∂–µ —Å–æ—Ö—Ä–∞–Ω–∏–º ‚Äî —ç—Ç–æ —ç–∫–æ–Ω–æ–º–∏—Ç –ª–∏–º–∏—Ç—ã
CACHE_FILE.write_text(json.dumps(geocache, ensure_ascii=False, indent=2), encoding="utf-8")

print("‚úÖ  events.json —Å–æ–∑–¥–∞–Ω/–æ–±–Ω–æ–≤–ª—ë–Ω")
