# scrape_vk.py  â–¸  Python 3.10+
# Ğ¡Ğ±Ğ¾Ñ€ Ğ°Ğ½Ğ¾Ğ½ÑĞ¾Ğ² VK + Â«ÑƒĞ¼Ğ½Ñ‹Ğ¹Â» Ğ³ĞµĞ¾ĞºĞ¾Ğ´ĞµÑ€ (ArcGIS â†’ Nominatim â†’ Ñ€ÑƒÑ‡Ğ½Ğ¾Ğ¹ ÑĞ¿Ñ€Ğ°Ğ²Ğ¾Ñ‡Ğ½Ğ¸Ğº)

import re, time, math, requests, pandas as pd
from geopy.geocoders import ArcGIS, Nominatim
from geopy.extra.rate_limiter import RateLimiter

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ĞĞĞ¡Ğ¢Ğ ĞĞ™ĞšĞ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TOKEN        = "vk1.a.az68uTKtqRoSRW7ud6qQBHBYEDX-IoB3n-raywQhtxBEfNEsIncINjLHPtxM6GA0lLaf_FjOY9H89xHnTq3c65AtgZzZ4BNxzgC8ThX56PY52S8yf3cZxbS4Utojhi83OiCUofSgsuBRXJldpIHtzuO70BBV8wR1DM9bdSMUhknZ7kb1e6ib9XBG2vnJSjXjhQ76en7c7VDcIMv-PqeCfQ"  # â† ÑĞ²Ğ¾Ğ¹
DOMAIN       = "meowrecords"
MAX_POSTS    = 2000
BATCH        = 100
WAIT_REQ     = 1.1                # Ğ¿Ğ°ÑƒĞ·Ğ° Ğ¼ĞµĞ¶Ğ´Ñƒ wall.get
YEAR_DEFAULT = "2025"

# Ñ€ÑƒÑ‡Ğ½Ñ‹Ğµ Ñ„Ğ¸ĞºÑÑ‹
MANUAL_FIX = {
    "Ğ³Ğ°Ğ»Ğ¸Ñ†ĞºĞ¾Ğ³Ğ¾ 18, ĞºĞ°Ğ»Ğ¸Ğ½Ğ¸Ğ½Ğ³Ñ€Ğ°Ğ´": (54.71428885362268, 20.49684969892652),
    "Ğ±Ğ°Ñ€Ğ°Ğ½Ğ¾Ğ²Ğ° 43Ğ°, ĞºĞ°Ğ»Ğ¸Ğ½Ğ¸Ğ½Ğ³Ñ€Ğ°Ğ´": (54.720663512417474, 20.507042646865408),
    "ÑÑ‘Ñ€Ñ„-ÑÑ‚Ğ°Ğ½Ñ†Ğ¸Ñ Ñ€Ğ°ÑÑĞ²ĞµÑ‚, Ğ¿Ğ¸Ğ¾Ğ½ĞµÑ€ÑĞºĞ¸Ğ¹ Ğ¿Ğ»ÑĞ¶": (54.95460237461884, 20.218043935955457)
}

# Ñ†ĞµĞ½Ñ‚Ñ€Ñ‹ Ğ³Ğ¾Ñ€Ğ¾Ğ´Ğ¾Ğ² Ğ´Ğ»Ñ Ğ²Ñ‹Ğ±Ğ¾Ñ€Ğ° Â«Ğ»ĞµĞ¿ÑˆĞµĞ³Ğ¾Â»
CENTER = {
    "ĞºĞ°Ğ»Ğ¸Ğ½Ğ¸Ğ½Ğ³Ñ€Ğ°Ğ´": (54.7100, 20.5100),
    "Ğ¿Ğ¸Ğ¾Ğ½ĞµÑ€ÑĞºĞ¸Ğ¹":  (54.9560, 20.2270)
}

# Ğ³ĞµĞ¾ĞºĞ¾Ğ´ĞµÑ€Ñ‹ Ñ RateLimiter
gis = RateLimiter(ArcGIS(timeout=10).geocode,                min_delay_seconds=1.0)
osm = RateLimiter(Nominatim(user_agent="meowafisha").geocode, min_delay_seconds=1.0)

vk_api = "https://api.vk.com/method/wall.get"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ VK Ğ¿Ğ°Ñ€ÑĞ¸Ğ½Ğ³ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def vk_wall(offset: int):
    prm = dict(domain=DOMAIN, offset=offset, count=BATCH,
               access_token=TOKEN, v="5.199")
    return requests.get(vk_api, params=prm, timeout=15).json()["response"]["items"]

def extract(text: str):
    m_date = re.search(r"\b(\d{2})\.(\d{2})\b", text)
    m_loc  = re.search(r"ğŸ“\s*(.+)", text)
    if not (m_date and m_loc):
        return None
    date  = f"{YEAR_DEFAULT}-{m_date.group(2)}-{m_date.group(1)}"
    loc   = m_loc.group(1).split('â¡ï¸')[0].strip()
    if not re.search(r"(ĞºĞ°Ğ»Ğ¸Ğ½Ğ¸Ğ½Ğ³Ñ€Ğ°Ğ´|Ğ¿Ğ¸Ğ¾Ğ½ĞµÑ€)", loc, re.I):
        loc += ", ĞšĞ°Ğ»Ğ¸Ğ½Ğ¸Ğ½Ğ³Ñ€Ğ°Ğ´"
    title = re.sub(r"^\d{2}\.\d{2}\s*\|\s*", "", text.split('\n')[0]).strip()
    return dict(title=title, date=date, location=loc)

records, off = [], 0
while off < MAX_POSTS:
    items = vk_wall(off)
    if not items:
        break
    for it in items:
        evt = extract(it["text"])
        if evt:
            records.append(evt)
    off += BATCH
    time.sleep(WAIT_REQ)

print("ĞĞ½Ğ¾Ğ½ÑĞ¾Ğ² Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ¾:", len(records))
df = pd.DataFrame(records).drop_duplicates()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Ğ“ĞµĞ¾ĞºĞ¾Ğ´ĞµÑ€ Â«ÑƒĞ¼Ğ½Ñ‹Ğ¹Â» â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def haversine(a, b):
    lat1, lon1 = a
    lat2, lon2 = b
    R = 6_371_000
    dlat = math.radians(lat2 - lat1)
    dlon = math.radians(lon2 - lon1)
    return 2 * R * math.asin(math.sqrt(
        math.sin(dlat / 2) ** 2 +
        math.cos(math.radians(lat1)) * math.cos(math.radians(lat2)) *
        math.sin(dlon / 2) ** 2))

def pick_best(addr, cands):
    city = "Ğ¿Ğ¸Ğ¾Ğ½ĞµÑ€ÑĞºĞ¸Ğ¹" if "Ğ¿Ğ¸Ğ¾Ğ½ĞµÑ€" in addr else "ĞºĞ°Ğ»Ğ¸Ğ½Ğ¸Ğ½Ğ³Ñ€Ğ°Ğ´"
    center = CENTER[city]
    return min(cands, key=lambda p: haversine(center, p))

def normalize(addr: str) -> str:
    addr = addr.lower().strip()
    addr = re.sub(r"\(.*?\)", "", addr)
    if "Ğ¿Ğ¸Ğ¾Ğ½ĞµÑ€" in addr and "Ğ¿Ğ¸Ğ¾Ğ½ĞµÑ€ÑĞºĞ¸Ğ¹" not in addr:
        addr += ", ĞŸĞ¸Ğ¾Ğ½ĞµÑ€ÑĞºĞ¸Ğ¹"
    if not re.search(r"(ĞºĞ°Ğ»Ğ¸Ğ½Ğ¸Ğ½Ğ³Ñ€Ğ°Ğ´|Ğ¿Ğ¸Ğ¾Ğ½ĞµÑ€ÑĞºĞ¸Ğ¹)", addr):
        addr += ", ĞšĞ°Ğ»Ğ¸Ğ½Ğ¸Ğ½Ğ³Ñ€Ğ°Ğ´"
    return addr

def smart_geocode(addr: str):
    norm = normalize(addr)
    if norm in MANUAL_FIX:
        return MANUAL_FIX[norm]
    cands = []
    try:
        g = gis(norm)
        if g:
            cands.append((g.latitude, g.longitude))
    except Exception:
        pass
    try:
        n = osm(norm)
        if n:
            cands.append((n.latitude, n.longitude))
    except Exception:
        pass
    if not cands:
        return (None, None)
    return pick_best(norm, cands)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ĞŸÑ€Ğ¸Ğ¼ĞµĞ½ÑĞµĞ¼ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
df[["lat", "lon"]] = df["location"].apply(lambda a: pd.Series(smart_geocode(a)))
bad_cnt = df["lat"].isna().sum()
df = df.dropna(subset=["lat", "lon"])

print(f"Ğ¡ ĞºĞ¾Ğ¾Ñ€Ğ´Ğ¸Ğ½Ğ°Ñ‚Ğ°Ğ¼Ğ¸: {len(df)} | Ğ±ĞµĞ· ĞºĞ¾Ğ¾Ñ€Ğ´Ğ¸Ğ½Ğ°Ñ‚: {bad_cnt}")

df[["title", "date", "location", "lat", "lon"]].to_json(
    "events.json", orient="records", force_ascii=False, indent=2)

print("âœ…  events.json ÑĞ¾Ğ·Ğ´Ğ°Ğ½")
